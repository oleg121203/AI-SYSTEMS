# AI-SYSTEMS

## Суть програми AI-SYSTEMS

AI-SYSTEMS — це комплексна система, розроблена для автоматизації процесу розробки програмного забезпечення за допомогою взаємодії кількох спеціалізованих AI-агентів. Основна мета — взяти на вхід опис цілі проекту (target) і згенерувати відповідну структуру проекту, написати код, створити тести, написати документацію та забезпечити ітеративне покращення коду на основі результатів тестування.

## Архітектура системи

Система складається з наступних основних компонентів:

- **AI1 (Координатор)**: Планує та координує задачі, приймає рішення на основі результатів тестування. Використовує LLM для гнучкого прийняття рішень, пріоритезації задач та аналізу звітів.
- **AI2 (Виконавці)**: Генерують код (executor), тести (tester) та документацію (documenter).
- **AI3 (Дозор/Менеджер структури)**: Створює структуру проекту, проактивно моніторить систему, надає консультації, виявляє проблеми та ініціює їх вирішення.
- **MCP API**: Центральне API для взаємодії між компонентами, керує чергами завдань.
- **Веб-інтерфейс**: Візуалізація процесу розробки та управління системою.
- **GitHub Actions**: Автоматизоване тестування коду.

## Структура репозиторіїв

Система використовує два репозиторії:

1. **Основний репозиторій (AI-SYSTEMS)**: 
   - Містить код самої системи (AI-агенти, API, веб-інтерфейс)
   - URL: `https://github.com/oleg121203/AI-SYSTEMS.git`

2. **Репозиторій проекту (repo/)**: 
   - Вкладений репозиторій, де зберігається згенерований проект
   - AI3 автоматично створює файли та робить коміти
   - URL: `https://github.com/oleg121203/AI-SYSTEMS-REPO.git`

## Конфігурація системи промптів

Система використовує гібридний підхід до управління промптами:

1. **Базові промпти в config.json**:
   - `ai1_prompt`: Базова інструкція для AI1-координатора. Описує цілі та повноваження AI1.
   - `ai2_prompts`: Масив базових інструкцій для AI2 (executor, tester, documenter).
   - `ai3_prompt`: Базова інструкція для AI3 щодо генерації структури проекту.

2. **Системні інструкції в коді**:
   - Кожен AI-агент доповнює базовий промпт системними інструкціями (наприклад, використання латиниці, формат JSON).
   - Це забезпечує гнучкість (основний промпт можна змінювати через конфігурацію) та надійність (критичні інструкції захищені в коді).

Приклад:
```python
# В ai1.py
self.system_prompt = config.get("ai1_prompt", "You are AI1, the project coordinator.")
self.system_instructions = " Use only Latin characters in your responses. Format your output as requested in specific prompts..."

# В ai2.py
self.base_prompts = self.config.get("ai2_prompts", [...])
self.system_instructions = " Respond ONLY with the raw file content. Do NOT use markdown code blocks..."

# В ai3.py
base_prompt_template = config.get("ai3_prompt", "Generate a JSON structure for a project with the target: \"{target}\".")
system_instructions = """Respond ONLY with the JSON structure itself..."""
```

## Алгоритм роботи системи

1. **Ініціалізація (AI3):**
   * AI3 отримує ціль проекту (`target`) з конфігурації.
   * Генерує початкову JSON-структуру файлів та директорій проекту за допомогою LLM.
   * Створює ці файли та директорії у локальному репозиторії (repo).
   * Відправляє згенеровану структуру в MCP API.
   * Запускає фонові процеси моніторингу:
     * **Паралельний моніторинг воркерів**: Безперервно перевіряє стан AI2-воркерів (executor, tester, documenter) через ендпоінт `/worker_status` в MCP API. Якщо виявляє простоюючих воркерів, запитує нові завдання через `/request_task_for_idle_worker`.
     * **Моніторинг логів**: Сканує логи на наявність помилок, пов'язаних з файлами в репозиторії проекту (repo/). Виявлені помилки негайно передаються AI1 через механізм колаборації.
     * **Моніторинг GitHub Actions**: Аналізує результати запусків CI/CD тестів в GitHub Actions (через GitHub API), включаючи детальний розбір логів на наявність помилок pytest, лінтингу (HTMLHint, Stylelint, ESLint) та інших проблем.
     * **Моніторинг черг**: Відстежує розміри черг завдань і, при виявленні перекосів (наприклад, перевантаження черги executor), повідомляє AI1 для перерозподілу завдань.

2. **Планування та координація (AI1):**
   * AI1 отримує структуру проекту від MCP API.
   * Будує високорівневу структуру основних завдань (наприклад, за компонентами: Backend, Frontend тощо).
   * **Взаємодія з AI3:** AI1 постійно отримує та обробляє звіти від AI3 (про результати тестів, системні помилки, стан черг, простоюючих воркерів) через ендпоінт `/ai_collaboration` в MCP API.
   * Розбиває кожну основну задачу на мікрозадачі (зазвичай пофайлово: реалізація, тестування, документування).
   * **Динамічна пріоритезація:** На основі звітів від AI3, AI1 динамічно коригує пріоритети завдань, наприклад, підвищуючи пріоритет виправлення помилок, виявлених під час моніторингу системи.
   * Ініціалізує статуси для всіх мікрозадач.

3. **Розподіл та виконання завдань (AI1 -> MCP API -> AI2):**
   * AI1 починає керувати завданнями (`manage_tasks`):
     * Визначає, які завдання готові до виконання (наприклад, "executor" для нового файлу, "tester" після завершення "executor").
     * Створює конкретні підзадачі (з промптами, ID, роллю, іменем файлу, іноді з кодом) та відправляє їх у MCP API.
   * MCP API розміщує підзадачі у відповідні черги (executor, tester, documenter).
   * AI2-воркери (запущені окремо для кожної ролі) періодично запитують завдання зі своєї черги у MCP API (`/task/{role}`).
   * Отримавши завдання, AI2-воркер використовує відповідний LLM-провайдер для генерації контенту (коду, тестів, документації).
   * AI2 відправляє звіт (`/report`) з результатом (згенерований контент або статус помилки) назад у MCP API.

4. **Обробка звітів та оновлення статусу (MCP API):**
   * MCP API отримує звіти від AI2 (`/report`).
   * Якщо звіт містить код (`type: code`), він записується у відповідний файл у репозиторії (repo) та комітиться за допомогою Git.
   * Статус відповідної підзадачі оновлюється (наприклад, `code_received`).
   * **Автоматичне створення наступних завдань:** Після отримання звіту з кодом від `executor`, MCP API **автоматично створює та ставить у чергу** нові завдання для `tester` та `documenter` для цього ж файлу. Така послідовність дозволяє паралельно працювати всім AI2-воркерам, підвищуючи загальну ефективність системи.
   * Оновлення статусу транслюється через WebSocket на веб-панель.

5. **Тестування (MCP API -> GitHub Actions -> AI3 -> MCP API -> AI1):**
   * Після того, як MCP API успішно записує та комітить код від AI2-executor в репозиторій проекту (`AI-SYSTEMS-REPO`), він **автоматично відправляє подію `repository_dispatch`** (типу `code-committed-in-repo`) до основного репозиторію `AI-SYSTEMS` (за умови наявності `GITHUB_TOKEN` та конфігурації `github_repo`).
   * Ця подія **тригерить запуск воркфлоу** `.github/workflows/python-tests.yml` в репозиторії `AI-SYSTEMS`.
   * Під час виконання воркфлоу завантажує код з обох репозиторіїв (`AI-SYSTEMS` в `main/`, `AI-SYSTEMS-REPO` в `repo/`).
   * Воркфлоу встановлює залежності для обох проектів.
   * Запускає `pytest` та лінтери для коду в `repo/` (модульні/інтеграційні тести).
   * **Запускає згенерований додаток** (наприклад, бекенд) у фоновому режимі.
   * **Запускає End-to-End (E2E) тести** (наприклад, за допомогою Playwright), які перевіряють роботу запущеного додатка.
   * Зупиняє фоновий процес додатка.
   * **AI3 моніторить GitHub Actions:** AI3 активно опитує GitHub API для отримання статусів запущених воркфлоу та аналізує їх результати. При завершенні запуску він:
     * Детально аналізує логи виконання, шукаючи конкретні помилки тестів (FAILURES, ERRORS), проблеми лінтингу для HTML/CSS/JS та інші проблеми.
     * Зіставляє знайдені помилки з конкретними файлами проекту, створюючи точний список файлів, які потребують виправлення.
     * На основі аналізу формує рекомендацію (`accept`/`rework`) та детальний контекст (які файли, які помилки, фрагменти логів).
   * AI3 відправляє рекомендацію в MCP API (`/test_recommendation`).
   * MCP API оновлює статус тестових завдань та пересилає рекомендацію AI1.

6. **Прийняття рішень та доопрацювання (AI1):**
   * AI1 отримує результати тестів та рекомендацію AI3 (`handle_test_result`).
   * AI1 приймає остаточне рішення (`decide_on_test_results`): прийняти код (`accept`) чи відправити на доопрацювання (`rework`).
   * Якщо `accept`, статус відповідних завдань оновлюється на `accepted`.
   * Якщо `rework`, статус оновлюється на `needs_rework`, і AI1 створює нову підзадачу для AI2-executor з описом необхідних виправлень (на основі коментарів AI3 або логів помилок). Ця нова задача знову проходить через цикл виконання та тестування.
   * AI1 періодично перевіряє, чи всі завдання досягли фінального статусу (`accepted` або `skipped`).

7. **Удосконалений моніторинг "Дозором" (AI3):**
   * Паралельно з усім процесом AI3 проводить активний моніторинг всієї системи:
     * **Моніторинг воркерів:** Регулярно перевіряє стан всіх воркерів через ендпоінт `/worker_status` в MCP API. При виявленні простоюючого воркера негайно запитує для нього нову задачу через `/request_task_for_idle_worker`.
     * **Резервне відстеження:** Якщо API для перевірки статусу недоступне, автоматично перемикається на резервний метод аналізу лог-файлів.
     * **Аналіз логів:** Постійно сканує логи всіх компонентів системи, використовуючи складні регулярні вирази для виявлення помилок, специфічно пов'язаних з файлами в репозиторії проекту (`repo/`).
     * **Проактивне вирішення проблем:** При виявленні критичних системних помилок, пов'язаних з файлами проекту, негайно повідомляє AI1 через ендпоінт `/ai_collaboration`, надаючи детальний контекст помилки та оточуючі рядки логу.
     * **Моніторинг розподілу завдань:** Відстежує розміри черг і, при виявленні перекосу (наприклад, переповнення черги executor), повідомляє AI1 для перебалансування.
     * **Відстеження GitHub Actions:** Безперервно моніторить статус та результати запусків воркфлоу CI/CD, аналізуючи їх логи на наявність конкретних помилок (як описано в п.5).

8. **Візуалізація (Dashboard):**
   * Веб-інтерфейс (`templates/index.html`, script.js, style.css) підключається до MCP API через WebSocket.
   * Відображає статуси AI-агентів, стан черг завдань, структуру файлів, логи, статистику та графіки прогресу в реальному часі.
   * Дозволяє користувачу керувати системою (старт/стоп агентів, скидання, редагування промптів).

## Інтеграція LLM для прийняття рішень в AI1

AI1 не лише використовує алгоритмічну логіку, але й застосовує LLM в ключових точках прийняття рішень:

1. **Аналіз результатів тестування**:
   - AI1 використовує LLM для аналізу результатів тестів і вирішення: прийняти код (`accept`), відправити на доопрацювання (`rework`) або вимагати ручного огляду (`manual_review`).
   - LLM отримує контекст: рекомендація AI3, файли з помилками, історія доопрацювань, загальна мета проекту.

2. **Пріоритезація завдань**:
   - AI1 використовує LLM для визначення пріоритетів завдань (executor, tester, documenter) в кожному циклі.
   - LLM враховує поточний стан проекту, залежності між завданнями, статистику помилок.

3. **Генерація тексту завдань**:
   - AI1 може використовувати LLM для формування детальних інструкцій для AI2, особливо при призначенні завдань на доопрацювання.

Цей підхід робить систему більш "живою" та адаптивною, здатною приймати рішення, схожі на людські, зберігаючи при цьому структурованість процесу.

## Розширені функції системи

### Управління середовищем розробки
* **Dev Container**: Система працює у контейнеризованому середовищі з усіма необхідними інструментами (Git, Docker, Python, Node.js, Go, Rust)
* **Автоматична настройка**: Скрипти для автоматичного налаштування середовища розробки

### Робота з LLM-провайдерами
* **Підтримка кількох LLM**: Можливість налаштування різних LLM для різних типів задач (код, тести, документація)
* **Ротація API-ключів**: Автоматичне перемикання між кількома API-ключами для уникнення лімітів
* **Кешування запитів**: Зменшення кількості запитів до LLM через збереження попередніх результатів

### Підтримка мультимовності
* **Багатомовні проекти**: Підтримка генерації проектів на різних мовах програмування
* **Локалізація веб-інтерфейсу**: Можливість вибору мови інтерфейсу

### Розширені можливості тестування
* **Аналіз покриття коду**: Інтеграція з інструментами аналізу покриття коду
* **Статичний аналіз**: Використання лінтерів та інших інструментів статичного аналізу
* **Інтеграційні тести**: Генерація та запуск інтеграційних тестів у воркфлоу.
* **End-to-End (E2E) Тести**: Воркфлоу автоматично запускає згенерований додаток та виконує E2E тести (наприклад, за допомогою Playwright) для перевірки його функціональності як єдиного цілого.

### Інструменти для розробників
* **CLI інтерфейс**: Управління системою через командний рядок 
* **Експорт/імпорт проектів**: Можливість експортувати та імпортувати проекти
* **Розширена аналітика**: Детальна статистика та метрики процесу розробки
* **Форматування кодових блоків**: Функція `format_code_blocks` (у `utils.py`) автоматично виправляє форматування кодових блоків Markdown, додаючи пробіл між назвою мови і потрійними зворотними лапками (наприклад, ```python -> ``` python). Це дозволяє уникнути проблем з парсингом коду в AI-системі.

#### Приклад використання:
```python
# В utils.py
import re

def format_code_blocks(text: str) -> str:
    """
    Ensures there is a space after the language identifier in markdown code blocks.
    Example: ```python -> ``` python
    Handles blocks with or without language identifiers.
    """
    pattern = r"(```)(\\S+)(\\s*\\n)"
    def replace_func(match):
        return f"{match.group(1)} {match.group(2)}{match.group(3)}"
    formatted_text = re.sub(pattern, replace_func, text)
    formatted_text = re.sub(r"(```)(?!\\s)(\\S)", r"\\1 \\2", formatted_text)
    return formatted_text

# Приклад виклику
example_text = """```python\nprint('Hello')\n```"""
formatted = format_code_blocks(example_text)
print(formatted) 
# Виведе:
# ``` python
# print('Hello')
# ```
```

## Налаштування та запуск

### Вимоги до системи
* Docker
* Git
* Python 3.10+
* Node.js 18+
* Змінна середовища `GITHUB_TOKEN` (з правами `repo` та `workflow`) для запуску GitHub Actions.

### Швидкий старт
```bash
# Клонування репозиторію
git clone https://github.com/oleg121203/AI-SYSTEMS.git
cd AI-SYSTEMS

# Створіть файл .env та додайте ваш GITHUB_TOKEN
echo "GITHUB_TOKEN=ghp_YourGitHubPersonalAccessToken" > .env

# Налаштування середовища (може потребувати sudo)
# ./setup.sh # Якщо потрібно встановити залежності

# Запуск системи (переконайтесь, що Docker запущено)
# ./start.sh --target "Опис вашого проекту" # Або використовуйте конфігурацію в config.json
# Або запустіть компоненти окремо:
# python mcp_api.py &
# python ai1.py &
# python ai3.py &
# python ai2.py --role executor &
# python ai2.py --role tester &
# python ai2.py --role documenter &
```

## Оцінка побудови системи

### Сильні сторони
* **Модульність:** Чіткий поділ відповідальності між AI-агентами (AI1 - координація, AI2 - виконання, AI3 - структура та моніторинг).
* **Автоматизація:** Повна автоматизація циклу розробки від структури до тестування та доопрацювання.
* **Гнучкість промптів:** Гібридний підхід до системи промптів дозволяє змінювати основні інструкції через config.json, зберігаючи критичні системні вимоги в коді.
* **Інтеграція LLM для прийняття рішень:** AI1 використовує LLM для "живих" рішень у ключових моментах, що робить систему більш адаптивною.
* **Зворотний зв'язок:** Замкнутий цикл тестування через GitHub Actions та аналіз результатів AI3 дозволяє системі самостійно покращувати код.
* **Проактивний моніторинг:** AI3 як "дозор" системи не лише пасивно реагує на проблеми, але й активно виявляє та адресує: простої воркерів, перекоси черг, помилки в логах, проблеми CI/CD.
* **Багаторівнева взаємодія:** Механізм колаборації (`/ai_collaboration`) дозволяє AI3 ефективно передавати AI1 важливі знахідки моніторингу для прийняття рішень.
* **Стійкість до збоїв:** Резервні методи (наприклад, аналіз логів при недоступності API), забезпечують безперервну роботу системи навіть при збоях окремих компонентів.
* **Централізоване API:** MCP API слугує єдиною точкою взаємодії, спрощуючи комунікацію.
* **Візуалізація:** Дашборд надає гарний огляд стану системи.
* **Автоматичне створення наступних завдань:** Система автоматично створює завдання для тестувальника та документатора одразу після отримання коду, забезпечуючи безперервний процес розробки.
* **Детальний аналіз помилок CI/CD:** AI3 глибоко аналізує результати тестів в GitHub Actions, включаючи розбір логів тестування та лінтингу для точної ідентифікації проблем.
* **Автоматична інтеграція з GitHub Actions:** Повністю автоматизований запуск CI/CD тестів після коміту коду через механізм repository_dispatch.

### Області для покращення
* **Складність:** Система досить складна через велику кількість взаємодіючих компонентів. Відладка та підтримка можуть бути непростими.
* **Надійність LLM:** Якість кінцевого продукту сильно залежить від якості генерації коду/тестів/документації базовими LLM. Потрібне ретельне налаштування промптів.
* **Обробка помилок:** Хоча система має багато механізмів виявлення помилок, комплексна обробка всіх типів помилок залишається складною.
* **Ефективність доопрацювання:** Механізм доопрацювання (коли AI1 створює нову задачу на виправлення) має бути ефективним, щоб не зациклюватися на одних і тих самих помилках. Можливо, потрібні складніші стратегії виправлення.
* **Управління станом:** Синхронізація стану між усіма компонентами (особливо статуси завдань) є критично важливою і може бути складною.
* **Масштабованість:** Зі збільшенням розміру проекту може зрости навантаження на API та LLM-провайдерів.
* **Оптимізація GitHub Actions:** Поточний воркфлоу може бути оптимізований для запуску тестів лише для файлів, пов'язаних зі зміненим кодом, а не для всіх файлів.
* **Баланс ресурсів моніторингу:** Активний моніторинг AI3 споживає ресурси системи. Потрібен розумний баланс між частотою перевірок та навантаженням.

## Плани розвитку

### Короткострокові
* Вдосконалення балансування ресурсів моніторингу AI3 для зменшення загального навантаження на систему.
* Покращення системи обробки помилок на всіх етапах.
* Розширення набору підтримуваних мов програмування.
* Оптимізація процесу тестування в GitHub Actions (запуск лише релевантних тестів).

### Середньострокові
* Інтеграція з іншими CI/CD системами (крім GitHub Actions).
* Впровадження механізмів машинного навчання для покращення якості генерації та пріоритезації.
* Додавання підтримки мобільної розробки.

### Довгострокові
* Розробка плагінів для популярних IDE.
* Створення маркетплейсу шаблонів проектів.
* Підтримка розподіленої розробки кількома командами.

## Внесок у проект

Ми раді будь-якому внеску в проект! Додаткову інформацію можна знайти в файлі CONTRIBUTING.md.

## Ліцензія

Проект розповсюджується під ліцензією MIT. Детальну інформацію можна знайти в файлі LICENSE.

## Висновок

Система AI-SYSTEMS має продуману архітектуру з чітким розподілом ролей та автоматизованим циклом розробки з тестуванням і доопрацюванням. Особливо сильними сторонами є проактивний моніторинг з боку AI3, який виявляє проблеми на ранніх етапах, та детальний аналіз результатів тестування для цілеспрямованого покращення коду. Хоча система є складною, ця складність виправдана багатим функціоналом та гнучкістю всіх компонентів. Загалом, це амбітний та добре структурований підхід до автоматизації створення ПЗ за допомогою AI.